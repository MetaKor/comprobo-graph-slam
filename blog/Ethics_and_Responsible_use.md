# Primary Ethical Concerns

The ethical ramifications of our graph slam project entirely revolve around the computer vision and pattern recognition (CVPR) section 2 guidelines and concerns as our project does not rely on any human data nor could it be used to exacerbate biases against any person or group that pertain to section 3. In short, this means there are concerns related to weapon system applications, privacy concerns, and, by extension, human right concerns. 

To begin, it is important to understand what graph slam even is. Graph slam is the problem of determining where a camera was at a certain time based on what it was seeing at that moment. For example, if a camera saw the Eiffel tower at 2pm and then the Arc de Triomphe at 3pm, we know that the camera had to travel some path between these two known points within the given difference in time. In the real world, we are taking hundreds of photos every minute and are identifying many landmarks that allow us to extrapolate far more granular movement.

It may not be immediately apparent as graph slam seems relatively mundane, but it has a wide range of ethical implications when applied to humans or military applications. Graph slam has the potential to be applied to military autonomous systems. For example, say that a drone was traveling inside a building trying to identify targets for the military to strike. Being inside, the drone cannot accurately rely on its global positioning system (GPS), but it could use graph slam to identify where it is within a building as well as where a potential combatant is in that building. Of course, the fact that this technique could be used to track a target's position or could misidentify a target raises serious ethical concerns about the use of this technique in military applications.

When it comes to graph slam, privacy and human rights concerns are of the same nature. Primarily, graph slam could be applied to accurately identify where a human is at any time in relation to the landmarks around them (i.e. graph slam has a robust ability to track human beings). Our application of graph slam only relates the position of a landmark and the camera, but it only takes some simple geometry to find the position of any human in the frame. Unlike GPS, which has a wide range of inaccuracies in dense urban environments, imaging cameras have no similar shortcomings and can identify the position of the human as long as they are in frame. With millions of cameras, a person could have no hope of privacy or anonymity in their life. With no privacy, human rights are imperiled. An entity could easily reprimand a person for patronizing a certain business, participating in a protest, or leaving their workplace early. Without privacy, it is almost impossible to have robust human rights. This is already a reality in countries such as China and is being rapidly adopted by countries that prefer to control their populations rather than serve them. It is imperative that graph slam is not allowed to become normalized in these applications as it provides a ripe environment for abuse. Strengthening protections for data privacy related to humans can go a long way in preventing this misuse. 

# Licensing and use

In principle, our code should only be used in open source applications that do not involve human subjects with further specifics being within the terms of the MIT standard software license. As long as our software is not being applied to human subjects or within the context of a larger application that intends to harm, track, or interact with humans, we do not see any other reasonable limitation to use of our software. We hope our software can help others in understanding what graph SLAM is and how it can further our understanding of sensors relation to their physical world. 
