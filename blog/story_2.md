# Project Story 2

## GraphSLAM in Python: data structures!

Now that we have acquired a pretty good grasp on how GraphSLAM works as explored in our [previous blog post](URL), it is time to dive into the question of how to represent the requisite mathematical objects in Python code. In many ways this seems to be one of the toughest tasks when implementing a mathematical algorithm, as there is so much flexibility in how one could choose to programatically represent things. This is traditionally thought of as the realm of "data structures and algorithms"

## Robust Object Matching

The main problem I have been grappling within this part of the project is how to efficiently recognize and then match the objects in an image frame with the known objects we want to track. For simplicity, I decided that only monochromatic pool balls would be used, but this still proved challenging to implement. This challenge can be broken into two main aspects: identifying objects of interest in a live video feed and consistently matching an object with its proper match. Identifying an object within an image frame is difficult because any logic must be light enough that it doesn't freeze or impede the video stream itself, so the processing ideally should be as close to realtime as possible. In addition, the logic itself must consistently be able to identify an object in an efficent manner. Currently, we are using the Hough transformation method that attempts to fit a continous curve the an image gradient. Hough transforms can be used for straight or curved lines, but we are using a specific version meant for identifying circles in an image frame. Currently, I am running into many headaches with the function not returning any circles even when the sensitivity is lowered, but I hope to address this through processing the image input. Once the circles are identified, the center color of each of them will be compared to the primary color of the landmark objects. This is where the second challenge comes into place as a tolerance has to be set that excludes mismatches but also includes the training landmarks. If time allows I would like to include code that dynamically adjusts the tolerance until there is no change in the number of pixels; thus, the full object would be identified. All in all, I hope to soon move on to finding the angle and distance to the objects after they are identified in relation to the camera. 
